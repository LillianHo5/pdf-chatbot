'''
streamlit_app.py: Simple web-based user interface for the PDF chatbot using Streamlit

The UI allows users to ask questions about a PDF document and get answers generated by a local LLM (via Ollama) - combined with RAG.
'''
import streamlit as st
from chatbot_core import build_qa_chain
import tempfile 
import time

st.set_page_config(page_title="PDF-Chatbot", layout="wide")
st.title("Chat with your PDF")
st.write("Upload a PDF file and ask questions about its content.")

uploaded_file = st.file_uploader("Upload a file", type="pdf")

if uploaded_file is not None:
    progress_bar = st.progress(0)
    for i in range(100):
        progress_bar.progress(i + 1)
        time.sleep(0.01)
    progress_bar.empty()

if uploaded_file is not None:
    if "last_uploaded_file" not in st.session_state or st.session_state.last_uploaded_file != uploaded_file.name:
        # Reset chat history for a new file
        st.session_state.chat_history = []
        st.session_state["input"] = "" 
        st.session_state.last_uploaded_file = uploaded_file.name
        
    # Save the uploaded file to a temporary location
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
        temp_file.write(uploaded_file.read())
        temp_file_path = temp_file.name

    # Build the QA chain using the temporary file path
    qa_chain = build_qa_chain(temp_file_path)

    # Initialize the chat history in Streamlit's session state
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # Create a text input field for the user to ask a question
    question = st.text_input("What would you like to know?", key="input")

    # If a question is submitted, process 
    if question:
        with st.spinner("Processing your question..."):
            result = qa_chain({
                "question": question,
                "chat_history": st.session_state.chat_history
            })

        st.session_state.chat_history.append((question, result["answer"]))

        # Display the chat history in reverse order
        for i, (q, a) in enumerate(st.session_state.chat_history[::-1]):
            st.markdown(f"**Question {len(st.session_state.chat_history) - i}:** {q}")
            st.markdown(f"**Answer:** {a}")
else:
    st.write("Please upload a PDF file to start.")